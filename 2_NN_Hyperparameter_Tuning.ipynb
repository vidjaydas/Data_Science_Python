{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "2.NN_Hyperparameter Tuning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vidjaydas/Data_Science_Python/blob/main/2_NN_Hyperparameter_Tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcRW8IdKoLO3"
      },
      "source": [
        "# Importing the necessary packages\n",
        "import pandas as pd\n",
        "import keras\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zLJ8aS16oLO_"
      },
      "source": [
        "# load pima indians dataset\n",
        "dataset = np.loadtxt(\"/content/pima-indians-diabetes.data.csv\", delimiter=\",\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ855rwQoLPA"
      },
      "source": [
        "X = dataset[:,0:8]\n",
        "y = dataset[:,8]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXGzabDDoLPB"
      },
      "source": [
        "# Standardization\n",
        "a = StandardScaler()\n",
        "a.fit(X)\n",
        "X_standardized = a.transform(X)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "gMPYCPr8oLPC",
        "outputId": "bf4b6367-59b6-45a9-ec1d-06c5283e0dce"
      },
      "source": [
        "pd.DataFrame(X_standardized).describe()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "      <td>7.680000e+02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-7.748432e-17</td>\n",
              "      <td>3.614007e-18</td>\n",
              "      <td>-1.327244e-17</td>\n",
              "      <td>7.762888e-17</td>\n",
              "      <td>-5.493291e-17</td>\n",
              "      <td>2.972738e-15</td>\n",
              "      <td>1.924387e-15</td>\n",
              "      <td>2.192980e-16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "      <td>1.000652e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.141852e+00</td>\n",
              "      <td>-3.783654e+00</td>\n",
              "      <td>-3.572597e+00</td>\n",
              "      <td>-1.288212e+00</td>\n",
              "      <td>-6.928906e-01</td>\n",
              "      <td>-4.060474e+00</td>\n",
              "      <td>-1.189553e+00</td>\n",
              "      <td>-1.041549e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-8.448851e-01</td>\n",
              "      <td>-6.852363e-01</td>\n",
              "      <td>-3.673367e-01</td>\n",
              "      <td>-1.288212e+00</td>\n",
              "      <td>-6.928906e-01</td>\n",
              "      <td>-5.955785e-01</td>\n",
              "      <td>-6.889685e-01</td>\n",
              "      <td>-7.862862e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-2.509521e-01</td>\n",
              "      <td>-1.218877e-01</td>\n",
              "      <td>1.496408e-01</td>\n",
              "      <td>1.545332e-01</td>\n",
              "      <td>-4.280622e-01</td>\n",
              "      <td>9.419788e-04</td>\n",
              "      <td>-3.001282e-01</td>\n",
              "      <td>-3.608474e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.399473e-01</td>\n",
              "      <td>6.057709e-01</td>\n",
              "      <td>5.632228e-01</td>\n",
              "      <td>7.190857e-01</td>\n",
              "      <td>4.120079e-01</td>\n",
              "      <td>5.847705e-01</td>\n",
              "      <td>4.662269e-01</td>\n",
              "      <td>6.602056e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.906578e+00</td>\n",
              "      <td>2.444478e+00</td>\n",
              "      <td>2.734528e+00</td>\n",
              "      <td>4.921866e+00</td>\n",
              "      <td>6.652839e+00</td>\n",
              "      <td>4.455807e+00</td>\n",
              "      <td>5.883565e+00</td>\n",
              "      <td>4.063716e+00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  0             1  ...             6             7\n",
              "count  7.680000e+02  7.680000e+02  ...  7.680000e+02  7.680000e+02\n",
              "mean  -7.748432e-17  3.614007e-18  ...  1.924387e-15  2.192980e-16\n",
              "std    1.000652e+00  1.000652e+00  ...  1.000652e+00  1.000652e+00\n",
              "min   -1.141852e+00 -3.783654e+00  ... -1.189553e+00 -1.041549e+00\n",
              "25%   -8.448851e-01 -6.852363e-01  ... -6.889685e-01 -7.862862e-01\n",
              "50%   -2.509521e-01 -1.218877e-01  ... -3.001282e-01 -3.608474e-01\n",
              "75%    6.399473e-01  6.057709e-01  ...  4.662269e-01  6.602056e-01\n",
              "max    3.906578e+00  2.444478e+00  ...  5.883565e+00  4.063716e+00\n",
              "\n",
              "[8 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9PzUUSuoLPD"
      },
      "source": [
        "#### Tuning of Hyperparameters :- Batch Size and Epochs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4U1deOCoLPE"
      },
      "source": [
        "# Importing the necessary packages\n",
        "from sklearn.model_selection import GridSearchCV, KFold\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import Adam"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GB6zI08eoLPF"
      },
      "source": [
        "# create model\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(12, input_dim=8, init='uniform', activation='relu'))\n",
        "    model.add(Dense(8, init='uniform', activation='relu'))\n",
        "    model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
        "    \n",
        "    adam=Adam(lr=0.01)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xrrejAiooLPG",
        "outputId": "dd4804e3-33a0-4c43-e615-2e9e7cc1b98d"
      },
      "source": [
        "# Create the model\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
        "# Define the grid search parameters\n",
        "batch_size = [10,20,40]\n",
        "epochs = [10,50,100]\n",
        "# Make a dictionary of the grid search parameters\n",
        "param_grid = dict(batch_size = batch_size,epochs = epochs)\n",
        "# Build and fit the GridSearchCV\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grid,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,y)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV] batch_size=10, epochs=10 ........................................\n",
            "[CV] .............. batch_size=10, epochs=10, score=nan, total=   0.0s\n",
            "[CV] batch_size=10, epochs=10 ........................................\n",
            "[CV] .............. batch_size=10, epochs=10, score=nan, total=   0.0s\n",
            "[CV] batch_size=10, epochs=10 ........................................\n",
            "[CV] .............. batch_size=10, epochs=10, score=nan, total=   0.0s\n",
            "[CV] batch_size=10, epochs=10 ........................................\n",
            "[CV] .............. batch_size=10, epochs=10, score=nan, total=   0.0s\n",
            "[CV] batch_size=10, epochs=10 ........................................\n",
            "[CV] .............. batch_size=10, epochs=10, score=nan, total=   0.0s\n",
            "[CV] batch_size=10, epochs=50 ........................................\n",
            "[CV] .............. batch_size=10, epochs=50, score=nan, total=   0.0s\n",
            "[CV] batch_size=10, epochs=50 ........................................\n",
            "[CV] .............. batch_size=10, epochs=50, score=nan, total=   0.0s\n",
            "[CV] batch_size=10, epochs=50 ........................................\n",
            "[CV] .............. batch_size=10, epochs=50, score=nan, total=   0.0s\n",
            "[CV] batch_size=10, epochs=50 ........................................\n",
            "[CV] .............. batch_size=10, epochs=50, score=nan, total=   0.0s\n",
            "[CV] batch_size=10, epochs=50 ........................................\n",
            "[CV] .............. batch_size=10, epochs=50, score=nan, total=   0.0s\n",
            "[CV] batch_size=10, epochs=100 .......................................\n",
            "[CV] ............. batch_size=10, epochs=100, score=nan, total=   0.0s\n",
            "[CV] batch_size=10, epochs=100 .......................................\n",
            "[CV] ............. batch_size=10, epochs=100, score=nan, total=   0.0s\n",
            "[CV] batch_size=10, epochs=100 .......................................\n",
            "[CV] ............. batch_size=10, epochs=100, score=nan, total=   0.0s\n",
            "[CV] batch_size=10, epochs=100 .......................................\n",
            "[CV] ............. batch_size=10, epochs=100, score=nan, total=   0.0s\n",
            "[CV] batch_size=10, epochs=100 .......................................\n",
            "[CV] ............. batch_size=10, epochs=100, score=nan, total=   0.0s\n",
            "[CV] batch_size=20, epochs=10 ........................................\n",
            "[CV] .............. batch_size=20, epochs=10, score=nan, total=   0.0s\n",
            "[CV] batch_size=20, epochs=10 ........................................\n",
            "[CV] .............. batch_size=20, epochs=10, score=nan, total=   0.0s\n",
            "[CV] batch_size=20, epochs=10 ........................................\n",
            "[CV] .............. batch_size=20, epochs=10, score=nan, total=   0.0s\n",
            "[CV] batch_size=20, epochs=10 ........................................\n",
            "[CV] .............. batch_size=20, epochs=10, score=nan, total=   0.0s\n",
            "[CV] batch_size=20, epochs=10 ........................................\n",
            "[CV] .............. batch_size=20, epochs=10, score=nan, total=   0.0s\n",
            "[CV] batch_size=20, epochs=50 ........................................\n",
            "[CV] .............. batch_size=20, epochs=50, score=nan, total=   0.0s\n",
            "[CV] batch_size=20, epochs=50 ........................................\n",
            "[CV] .............. batch_size=20, epochs=50, score=nan, total=   0.0s\n",
            "[CV] batch_size=20, epochs=50 ........................................\n",
            "[CV] .............. batch_size=20, epochs=50, score=nan, total=   0.0s\n",
            "[CV] batch_size=20, epochs=50 ........................................\n",
            "[CV] .............. batch_size=20, epochs=50, score=nan, total=   0.0s\n",
            "[CV] batch_size=20, epochs=50 ........................................\n",
            "[CV] .............. batch_size=20, epochs=50, score=nan, total=   0.0s\n",
            "[CV] batch_size=20, epochs=100 .......................................\n",
            "[CV] ............. batch_size=20, epochs=100, score=nan, total=   0.0s\n",
            "[CV] batch_size=20, epochs=100 .......................................\n",
            "[CV] ............. batch_size=20, epochs=100, score=nan, total=   0.0s\n",
            "[CV] batch_size=20, epochs=100 .......................................\n",
            "[CV] ............. batch_size=20, epochs=100, score=nan, total=   0.0s\n",
            "[CV] batch_size=20, epochs=100 .......................................\n",
            "[CV] ............. batch_size=20, epochs=100, score=nan, total=   0.0s\n",
            "[CV] batch_size=20, epochs=100 .......................................\n",
            "[CV] ............. batch_size=20, epochs=100, score=nan, total=   0.0s\n",
            "[CV] batch_size=40, epochs=10 ........................................\n",
            "[CV] .............. batch_size=40, epochs=10, score=nan, total=   0.0s\n",
            "[CV] batch_size=40, epochs=10 ........................................\n",
            "[CV] .............. batch_size=40, epochs=10, score=nan, total=   0.0s\n",
            "[CV] batch_size=40, epochs=10 ........................................\n",
            "[CV] .............. batch_size=40, epochs=10, score=nan, total=   0.0s\n",
            "[CV] batch_size=40, epochs=10 ........................................\n",
            "[CV] .............. batch_size=40, epochs=10, score=nan, total=   0.0s\n",
            "[CV] batch_size=40, epochs=10 ........................................\n",
            "[CV] .............. batch_size=40, epochs=10, score=nan, total=   0.0s\n",
            "[CV] batch_size=40, epochs=50 ........................................\n",
            "[CV] .............. batch_size=40, epochs=50, score=nan, total=   0.0s\n",
            "[CV] batch_size=40, epochs=50 ........................................\n",
            "[CV] .............. batch_size=40, epochs=50, score=nan, total=   0.0s\n",
            "[CV] batch_size=40, epochs=50 ........................................\n",
            "[CV] .............. batch_size=40, epochs=50, score=nan, total=   0.0s\n",
            "[CV] batch_size=40, epochs=50 ........................................\n",
            "[CV] .............. batch_size=40, epochs=50, score=nan, total=   0.0s\n",
            "[CV] batch_size=40, epochs=50 ........................................\n",
            "[CV] .............. batch_size=40, epochs=50, score=nan, total=   0.0s\n",
            "[CV] batch_size=40, epochs=100 .......................................\n",
            "[CV] ............. batch_size=40, epochs=100, score=nan, total=   0.0s\n",
            "[CV] batch_size=40, epochs=100 .......................................\n",
            "[CV] ............. batch_size=40, epochs=100, score=nan, total=   0.0s\n",
            "[CV] batch_size=40, epochs=100 .......................................\n",
            "[CV] ............. batch_size=40, epochs=100, score=nan, total=   0.0s\n",
            "[CV] batch_size=40, epochs=100 .......................................\n",
            "[CV] ............. batch_size=40, epochs=100, score=nan, total=   0.0s\n",
            "[CV] batch_size=40, epochs=100 .......................................\n",
            "[CV] ............. batch_size=40, epochs=100, score=nan, total=   0.0s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "TypeError: ('Keyword argument not understood:', 'init')\n",
            "\n",
            "  FitFailedWarning)\n",
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:    0.0s remaining:    0.0s\n",
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:    0.1s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-0efede6617b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Build and fit the GridSearchCV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mgrid_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_standardized\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    740\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Invalid shape for y: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/wrappers/scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m           **self.filter_sk_params(self.build_fn.__call__))\n\u001b[1;32m    153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_sk_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m     if (losses.is_categorical_crossentropy(self.model.loss) and\n",
            "\u001b[0;32m<ipython-input-24-aee56e00d4c0>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uniform'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/layers/core.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, units, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m   1142\u001b[0m                **kwargs):\n\u001b[1;32m   1143\u001b[0m     super(Dense, self).__init__(\n\u001b[0;32m-> 1144\u001b[0;31m         activity_regularizer=activity_regularizer, **kwargs)\n\u001b[0m\u001b[1;32m   1145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1146\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    521\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 522\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    523\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, trainable, name, dtype, dynamic, **kwargs)\u001b[0m\n\u001b[1;32m    321\u001b[0m     }\n\u001b[1;32m    322\u001b[0m     \u001b[0;31m# Validate optional keyword arguments.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m     \u001b[0mgeneric_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;31m# Mutable properties\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mvalidate_kwargs\u001b[0;34m(kwargs, allowed_kwargs, error_message)\u001b[0m\n\u001b[1;32m   1132\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mkwarg\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mallowed_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: ('Keyword argument not understood:', 'init')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77Sgb6EvoLPH"
      },
      "source": [
        "# Summarize the results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8049Ym5_oLPI"
      },
      "source": [
        "#### Tuning of Hyperparameters:- Learning rate and Drop out rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xLD6UraoLPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f817f4e4-b812-460f-b70f-a1ad958c1192"
      },
      "source": [
        "from keras.layers import Dropout\n",
        "\n",
        "# Defining the model\n",
        "\n",
        "def create_model(learning_rate,dropout_rate):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8,input_dim = 8,kernel_initializer = 'normal',activation = 'relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(4,input_dim = 8,kernel_initializer = 'normal',activation = 'relu'))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = learning_rate)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
        "\n",
        "# Define the grid search parameters\n",
        "\n",
        "learning_rate = [0.001,0.01,0.1]\n",
        "dropout_rate = [0.0,0.1,0.2]\n",
        "\n",
        "# Make a dictionary of the grid search parameters\n",
        "\n",
        "param_grids = dict(learning_rate = learning_rate,dropout_rate = dropout_rate)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,y)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.792, total=   1.3s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.584, total=   1.2s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.630, total=   1.3s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.837, total=   1.3s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.001 ...........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    5.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.001, score=0.647, total=   1.4s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.766, total=   1.2s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    7.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.701, total=   1.2s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    9.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.753, total=   1.2s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   10.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.830, total=   1.5s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.01 ............................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   11.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  dropout_rate=0.0, learning_rate=0.01, score=0.758, total=   1.3s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.773, total=   1.3s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.701, total=   1.3s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.760, total=   1.3s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.863, total=   1.2s\n",
            "[CV] dropout_rate=0.0, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.0, learning_rate=0.1, score=0.647, total=   1.2s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.747, total=   1.4s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.688, total=   1.4s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.630, total=   1.7s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.745, total=   1.4s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.001, score=0.745, total=   1.4s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.721, total=   1.2s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.708, total=   1.2s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.753, total=   1.4s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.843, total=   1.2s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.1, learning_rate=0.01, score=0.752, total=   1.4s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.760, total=   1.2s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.734, total=   1.6s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.760, total=   1.3s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.843, total=   1.4s\n",
            "[CV] dropout_rate=0.1, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.1, learning_rate=0.1, score=0.725, total=   1.4s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.721, total=   1.4s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.584, total=   1.4s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.630, total=   1.4s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.804, total=   1.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.001 ...........................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.001, score=0.745, total=   1.7s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.747, total=   1.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.714, total=   1.4s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.753, total=   1.4s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.843, total=   1.4s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.01 ............................\n",
            "[CV]  dropout_rate=0.2, learning_rate=0.01, score=0.758, total=   1.4s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.734, total=   1.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.675, total=   1.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.760, total=   1.2s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.843, total=   1.6s\n",
            "[CV] dropout_rate=0.2, learning_rate=0.1 .............................\n",
            "[CV] . dropout_rate=0.2, learning_rate=0.1, score=0.765, total=   1.3s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:  1.0min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2gLM8VwoLPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f056583a-c7f8-4dec-fc37-f935a7ee2f70"
      },
      "source": [
        "# Summarize the results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best : 0.764374840259552, using {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
            "0.6980307221412658,0.09820746828679261 with: {'dropout_rate': 0.0, 'learning_rate': 0.001}\n",
            "0.7618028998374939,0.041052552055493664 with: {'dropout_rate': 0.0, 'learning_rate': 0.01}\n",
            "0.748714029788971,0.07250280992907586 with: {'dropout_rate': 0.0, 'learning_rate': 0.1}\n",
            "0.7110262393951416,0.046261139169753676 with: {'dropout_rate': 0.1, 'learning_rate': 0.001}\n",
            "0.7553178906440735,0.04728997918990282 with: {'dropout_rate': 0.1, 'learning_rate': 0.01}\n",
            "0.764374840259552,0.041702225833379424 with: {'dropout_rate': 0.1, 'learning_rate': 0.1}\n",
            "0.696816909313202,0.07936322865341362 with: {'dropout_rate': 0.2, 'learning_rate': 0.001}\n",
            "0.763118588924408,0.04284250835793969 with: {'dropout_rate': 0.2, 'learning_rate': 0.01}\n",
            "0.7553348660469055,0.05419099480340696 with: {'dropout_rate': 0.2, 'learning_rate': 0.1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F_RYfD6oLPL"
      },
      "source": [
        "#### Tuning of Hyperparameters:- Activation Function and Kernel Initializer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5l_CahVoLPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68114f5d-449b-4931-91a7-b2156aa402e1"
      },
      "source": [
        "# Defining the model\n",
        "\n",
        "def create_model(activation_function,init):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(8,input_dim = 8,kernel_initializer = init,activation = activation_function))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(4,input_dim = 8,kernel_initializer = init,activation = activation_function))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = 0.001)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
        "\n",
        "# Define the grid search parameters\n",
        "activation_function = ['softmax','relu','tanh','linear']\n",
        "init = ['uniform','normal','zero']\n",
        "\n",
        "# Make a dictionary of the grid search parameters\n",
        "param_grids = dict(activation_function = activation_function,init = init)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,y)\n",
        "\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "[CV] activation_function=softmax, init=uniform .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=uniform, score=0.649, total=   1.3s\n",
            "[CV] activation_function=softmax, init=uniform .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=uniform, score=0.416, total=   1.2s\n",
            "[CV] activation_function=softmax, init=uniform .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.6s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=uniform, score=0.630, total=   1.2s\n",
            "[CV] activation_function=softmax, init=uniform .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    3.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=uniform, score=0.745, total=   1.4s\n",
            "[CV] activation_function=softmax, init=uniform .......................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    5.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=uniform, score=0.647, total=   1.7s\n",
            "[CV] activation_function=softmax, init=normal ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.9s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=normal, score=0.649, total=   1.4s\n",
            "[CV] activation_function=softmax, init=normal ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    8.2s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=normal, score=0.584, total=   1.3s\n",
            "[CV] activation_function=softmax, init=normal ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    9.5s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=normal, score=0.630, total=   1.4s\n",
            "[CV] activation_function=softmax, init=normal ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   10.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=normal, score=0.745, total=   1.2s\n",
            "[CV] activation_function=softmax, init=normal ........................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   12.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV]  activation_function=softmax, init=normal, score=0.647, total=   1.3s\n",
            "[CV] activation_function=softmax, init=zero ..........................\n",
            "[CV]  activation_function=softmax, init=zero, score=0.649, total=   1.4s\n",
            "[CV] activation_function=softmax, init=zero ..........................\n",
            "[CV]  activation_function=softmax, init=zero, score=0.584, total=   1.2s\n",
            "[CV] activation_function=softmax, init=zero ..........................\n",
            "[CV]  activation_function=softmax, init=zero, score=0.630, total=   1.4s\n",
            "[CV] activation_function=softmax, init=zero ..........................\n",
            "[CV]  activation_function=softmax, init=zero, score=0.745, total=   1.7s\n",
            "[CV] activation_function=softmax, init=zero ..........................\n",
            "[CV]  activation_function=softmax, init=zero, score=0.647, total=   1.4s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=0.753, total=   1.4s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=0.584, total=   1.4s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=0.766, total=   1.2s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=0.745, total=   1.2s\n",
            "[CV] activation_function=relu, init=uniform ..........................\n",
            "[CV]  activation_function=relu, init=uniform, score=0.745, total=   1.4s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=0.760, total=   1.4s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=0.695, total=   1.5s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=0.675, total=   1.2s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=0.745, total=   1.2s\n",
            "[CV] activation_function=relu, init=normal ...........................\n",
            "[CV]  activation_function=relu, init=normal, score=0.752, total=   1.4s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV] . activation_function=relu, init=zero, score=0.649, total=   1.4s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV] . activation_function=relu, init=zero, score=0.584, total=   1.3s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV] . activation_function=relu, init=zero, score=0.630, total=   1.4s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV] . activation_function=relu, init=zero, score=0.745, total=   1.2s\n",
            "[CV] activation_function=relu, init=zero .............................\n",
            "[CV] . activation_function=relu, init=zero, score=0.647, total=   1.2s\n",
            "[CV] activation_function=tanh, init=uniform ..........................\n",
            "[CV]  activation_function=tanh, init=uniform, score=0.760, total=   1.5s\n",
            "[CV] activation_function=tanh, init=uniform ..........................\n",
            "[CV]  activation_function=tanh, init=uniform, score=0.688, total=   1.4s\n",
            "[CV] activation_function=tanh, init=uniform ..........................\n",
            "[CV]  activation_function=tanh, init=uniform, score=0.753, total=   1.2s\n",
            "[CV] activation_function=tanh, init=uniform ..........................\n",
            "[CV]  activation_function=tanh, init=uniform, score=0.843, total=   1.2s\n",
            "[CV] activation_function=tanh, init=uniform ..........................\n",
            "[CV]  activation_function=tanh, init=uniform, score=0.771, total=   1.3s\n",
            "[CV] activation_function=tanh, init=normal ...........................\n",
            "[CV]  activation_function=tanh, init=normal, score=0.740, total=   1.2s\n",
            "[CV] activation_function=tanh, init=normal ...........................\n",
            "[CV]  activation_function=tanh, init=normal, score=0.682, total=   1.2s\n",
            "[CV] activation_function=tanh, init=normal ...........................\n",
            "[CV]  activation_function=tanh, init=normal, score=0.760, total=   1.3s\n",
            "[CV] activation_function=tanh, init=normal ...........................\n",
            "[CV]  activation_function=tanh, init=normal, score=0.830, total=   1.2s\n",
            "[CV] activation_function=tanh, init=normal ...........................\n",
            "[CV]  activation_function=tanh, init=normal, score=0.784, total=   1.7s\n",
            "[CV] activation_function=tanh, init=zero .............................\n",
            "[CV] . activation_function=tanh, init=zero, score=0.649, total=   1.4s\n",
            "[CV] activation_function=tanh, init=zero .............................\n",
            "[CV] . activation_function=tanh, init=zero, score=0.584, total=   1.4s\n",
            "[CV] activation_function=tanh, init=zero .............................\n",
            "[CV] . activation_function=tanh, init=zero, score=0.630, total=   1.3s\n",
            "[CV] activation_function=tanh, init=zero .............................\n",
            "[CV] . activation_function=tanh, init=zero, score=0.745, total=   1.4s\n",
            "[CV] activation_function=tanh, init=zero .............................\n",
            "[CV] . activation_function=tanh, init=zero, score=0.647, total=   1.2s\n",
            "[CV] activation_function=linear, init=uniform ........................\n",
            "[CV]  activation_function=linear, init=uniform, score=0.753, total=   1.2s\n",
            "[CV] activation_function=linear, init=uniform ........................\n",
            "[CV]  activation_function=linear, init=uniform, score=0.688, total=   1.2s\n",
            "[CV] activation_function=linear, init=uniform ........................\n",
            "[CV]  activation_function=linear, init=uniform, score=0.760, total=   1.2s\n",
            "[CV] activation_function=linear, init=uniform ........................\n",
            "[CV]  activation_function=linear, init=uniform, score=0.824, total=   1.7s\n",
            "[CV] activation_function=linear, init=uniform ........................\n",
            "[CV]  activation_function=linear, init=uniform, score=0.758, total=   1.3s\n",
            "[CV] activation_function=linear, init=normal .........................\n",
            "[CV]  activation_function=linear, init=normal, score=0.740, total=   1.4s\n",
            "[CV] activation_function=linear, init=normal .........................\n",
            "[CV]  activation_function=linear, init=normal, score=0.688, total=   1.3s\n",
            "[CV] activation_function=linear, init=normal .........................\n",
            "[CV]  activation_function=linear, init=normal, score=0.740, total=   1.2s\n",
            "[CV] activation_function=linear, init=normal .........................\n",
            "[CV]  activation_function=linear, init=normal, score=0.830, total=   1.2s\n",
            "[CV] activation_function=linear, init=normal .........................\n",
            "[CV]  activation_function=linear, init=normal, score=0.752, total=   1.2s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=0.649, total=   1.2s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=0.584, total=   1.1s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=0.630, total=   1.5s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=0.745, total=   1.4s\n",
            "[CV] activation_function=linear, init=zero ...........................\n",
            "[CV]  activation_function=linear, init=zero, score=0.647, total=   1.2s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:  1.3min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bN5e4pGXoLPN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8bac28-03a3-484e-c23c-b388400f0fb7"
      },
      "source": [
        "# Summarize the results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best : 0.763135552406311, using {'activation_function': 'tanh', 'init': 'uniform'}\n",
            "0.6173924148082733,0.10871275688841411 with: {'activation_function': 'softmax', 'init': 'uniform'}\n",
            "0.6511586427688598,0.05244526932680711 with: {'activation_function': 'softmax', 'init': 'normal'}\n",
            "0.6511586427688598,0.05244526932680711 with: {'activation_function': 'softmax', 'init': 'zero'}\n",
            "0.7188184261322021,0.06764449634719838 with: {'activation_function': 'relu', 'init': 'uniform'}\n",
            "0.7253204345703125,0.033761029287922774 with: {'activation_function': 'relu', 'init': 'normal'}\n",
            "0.6511586427688598,0.05244526932680711 with: {'activation_function': 'relu', 'init': 'zero'}\n",
            "0.763135552406311,0.04934351516191288 with: {'activation_function': 'tanh', 'init': 'uniform'}\n",
            "0.7592394590377808,0.0489889006179166 with: {'activation_function': 'tanh', 'init': 'normal'}\n",
            "0.6511586427688598,0.05244526932680711 with: {'activation_function': 'tanh', 'init': 'zero'}\n",
            "0.7565996050834656,0.04281684314436169 with: {'activation_function': 'linear', 'init': 'uniform'}\n",
            "0.7501061201095581,0.045625142635473306 with: {'activation_function': 'linear', 'init': 'normal'}\n",
            "0.6511586427688598,0.05244526932680711 with: {'activation_function': 'linear', 'init': 'zero'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtF5YPuboLPO"
      },
      "source": [
        "#### Tuning of Hyperparameter :-Number of Neurons in activation layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqZmd9F4oLPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81354943-14fa-4b5c-f57d-a6bd35d9a03a"
      },
      "source": [
        "# Defining the model\n",
        "\n",
        "def create_model(neuron1,neuron2):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neuron1,input_dim = 8,kernel_initializer = 'uniform',activation = 'tanh'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = 'uniform',activation = 'tanh'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = 0.001)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
        "\n",
        "# Define the grid search parameters\n",
        "\n",
        "neuron1 = [4,8,16]\n",
        "neuron2 = [2,4,8]\n",
        "\n",
        "# Make a dictionary of the grid search parameters\n",
        "\n",
        "param_grids = dict(neuron1 = neuron1,neuron2 = neuron2)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,y)\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n",
            "[CV] neuron1=4, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=2, score=0.740, total=   1.4s\n",
            "[CV] neuron1=4, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    1.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=2, score=0.669, total=   1.4s\n",
            "[CV] neuron1=4, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    2.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=2, score=0.740, total=   1.3s\n",
            "[CV] neuron1=4, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    4.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=2, score=0.797, total=   1.2s\n",
            "[CV] neuron1=4, neuron2=2 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:    5.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=2, score=0.739, total=   1.5s\n",
            "[CV] neuron1=4, neuron2=4 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:    6.8s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=4, score=0.747, total=   1.4s\n",
            "[CV] neuron1=4, neuron2=4 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   6 out of   6 | elapsed:    8.1s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=4, score=0.662, total=   1.2s\n",
            "[CV] neuron1=4, neuron2=4 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   7 out of   7 | elapsed:    9.3s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=4, score=0.734, total=   1.3s\n",
            "[CV] neuron1=4, neuron2=4 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   10.7s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=4, score=0.797, total=   1.4s\n",
            "[CV] neuron1=4, neuron2=4 ............................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   12.0s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[CV] ................ neuron1=4, neuron2=4, score=0.745, total=   1.2s\n",
            "[CV] neuron1=4, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=4, neuron2=8, score=0.766, total=   1.2s\n",
            "[CV] neuron1=4, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=4, neuron2=8, score=0.675, total=   1.2s\n",
            "[CV] neuron1=4, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=4, neuron2=8, score=0.740, total=   1.2s\n",
            "[CV] neuron1=4, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=4, neuron2=8, score=0.817, total=   1.5s\n",
            "[CV] neuron1=4, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=4, neuron2=8, score=0.758, total=   1.2s\n",
            "[CV] neuron1=8, neuron2=2 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=2, score=0.760, total=   1.3s\n",
            "[CV] neuron1=8, neuron2=2 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=2, score=0.701, total=   1.2s\n",
            "[CV] neuron1=8, neuron2=2 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=2, score=0.727, total=   1.2s\n",
            "[CV] neuron1=8, neuron2=2 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=2, score=0.810, total=   1.3s\n",
            "[CV] neuron1=8, neuron2=2 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=2, score=0.771, total=   1.3s\n",
            "[CV] neuron1=8, neuron2=4 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=4, score=0.747, total=   1.3s\n",
            "[CV] neuron1=8, neuron2=4 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=4, score=0.675, total=   1.2s\n",
            "[CV] neuron1=8, neuron2=4 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=4, score=0.766, total=   1.7s\n",
            "[CV] neuron1=8, neuron2=4 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=4, score=0.810, total=   1.4s\n",
            "[CV] neuron1=8, neuron2=4 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=4, score=0.778, total=   1.2s\n",
            "[CV] neuron1=8, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=8, score=0.760, total=   1.2s\n",
            "[CV] neuron1=8, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=8, score=0.708, total=   1.3s\n",
            "[CV] neuron1=8, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=8, score=0.760, total=   1.2s\n",
            "[CV] neuron1=8, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=8, score=0.843, total=   1.3s\n",
            "[CV] neuron1=8, neuron2=8 ............................................\n",
            "[CV] ................ neuron1=8, neuron2=8, score=0.758, total=   1.2s\n",
            "[CV] neuron1=16, neuron2=2 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=2, score=0.766, total=   1.3s\n",
            "[CV] neuron1=16, neuron2=2 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=2, score=0.714, total=   1.7s\n",
            "[CV] neuron1=16, neuron2=2 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=2, score=0.747, total=   1.2s\n",
            "[CV] neuron1=16, neuron2=2 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=2, score=0.843, total=   1.4s\n",
            "[CV] neuron1=16, neuron2=2 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=2, score=0.765, total=   1.2s\n",
            "[CV] neuron1=16, neuron2=4 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=4, score=0.760, total=   1.2s\n",
            "[CV] neuron1=16, neuron2=4 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=4, score=0.708, total=   1.2s\n",
            "[CV] neuron1=16, neuron2=4 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=4, score=0.760, total=   1.2s\n",
            "[CV] neuron1=16, neuron2=4 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=4, score=0.843, total=   1.3s\n",
            "[CV] neuron1=16, neuron2=4 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=4, score=0.765, total=   1.4s\n",
            "[CV] neuron1=16, neuron2=8 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=8, score=0.773, total=   1.6s\n",
            "[CV] neuron1=16, neuron2=8 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=8, score=0.714, total=   1.4s\n",
            "[CV] neuron1=16, neuron2=8 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=8, score=0.753, total=   1.2s\n",
            "[CV] neuron1=16, neuron2=8 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=8, score=0.830, total=   1.2s\n",
            "[CV] neuron1=16, neuron2=8 ...........................................\n",
            "[CV] ............... neuron1=16, neuron2=8, score=0.739, total=   1.2s\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  45 out of  45 | elapsed:   58.8s finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qb7feO2NoLPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ef7154c-fce7-42cb-fb6e-db45b6ff1856"
      },
      "source": [
        "# Summarize the results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best : 0.7670231819152832, using {'neuron1': 16, 'neuron2': 2}\n",
            "0.7370596885681152,0.040785018402409744 with: {'neuron1': 4, 'neuron2': 2}\n",
            "0.7370681762695312,0.04334057748386194 with: {'neuron1': 4, 'neuron2': 4}\n",
            "0.7513963222503662,0.04578195138420501 with: {'neuron1': 4, 'neuron2': 8}\n",
            "0.7540022134780884,0.03744183591800754 with: {'neuron1': 8, 'neuron2': 2}\n",
            "0.7553094029426575,0.04502499036033127 with: {'neuron1': 8, 'neuron2': 4}\n",
            "0.7657159805297852,0.043537520865324045 with: {'neuron1': 8, 'neuron2': 8}\n",
            "0.7670231819152832,0.042406259828712656 with: {'neuron1': 16, 'neuron2': 2}\n",
            "0.7670231699943543,0.043389198132676055 with: {'neuron1': 16, 'neuron2': 4}\n",
            "0.7617774367332458,0.039116050089886965 with: {'neuron1': 16, 'neuron2': 8}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvIYADFfoLPR"
      },
      "source": [
        "#### Training model with optimum values of Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hiEhRUSoLPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f083ff59-838a-4c20-f5a5-03c7801b7c8c"
      },
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Defining the model\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(16,input_dim = 8,kernel_initializer = 'uniform',activation = 'tanh'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(4,input_dim = 16,kernel_initializer = 'uniform',activation = 'tanh'))\n",
        "    model.add(Dropout(0.1))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = 0.001) #sgd = SGD(lr=learning_rate, momentum=momentum, decay=decay_rate, nesterov=False)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0,batch_size = 40,epochs = 10)\n",
        "\n",
        "# Fitting the model\n",
        "\n",
        "model.fit(X_standardized,y)\n",
        "\n",
        "# Predicting using trained model\n",
        "\n",
        "y_predict = model.predict(X_standardized)\n",
        "\n",
        "# Printing the metrics\n",
        "print(accuracy_score(y,y_predict))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.77734375\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtPitQaxoLPS"
      },
      "source": [
        "# Hyperparameters all at once"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4yT86T5oLPT"
      },
      "source": [
        "\n",
        "The hyperparameter optimization was carried out by taking 2 hyperparameters at once. We may have missed the best values. The performance can be further improved by finding the optimum values of hyperparameters all at once given by the code snippet below.\n",
        "#### This process is computationally expensive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiZTm2spoLPT"
      },
      "source": [
        "def create_model(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(neuron1,input_dim = 8,kernel_initializer = init,activation = activation_function))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = init,activation = activation_function))\n",
        "    model.add(Dropout(dropout_rate))\n",
        "    model.add(Dense(1,activation = 'sigmoid'))\n",
        "    \n",
        "    adam = Adam(lr = learning_rate)\n",
        "    model.compile(loss = 'binary_crossentropy',optimizer = adam,metrics = ['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model = KerasClassifier(build_fn = create_model,verbose = 0)\n",
        "\n",
        "# Define the grid search parameters\n",
        "\n",
        "batch_size = [10,20,40]\n",
        "epochs = [10,50,100]\n",
        "learning_rate = [0.001,0.01,0.1]\n",
        "dropout_rate = [0.0,0.1,0.2]\n",
        "activation_function = ['softmax','relu','tanh','linear']\n",
        "init = ['uniform','normal','zero']\n",
        "neuron1 = [4,8,16]\n",
        "neuron2 = [2,4,8]\n",
        "\n",
        "# Make a dictionary of the grid search parameters\n",
        "\n",
        "param_grids = dict(batch_size = batch_size,epochs = epochs,learning_rate = learning_rate,dropout_rate = dropout_rate,\n",
        "                   activation_function = activation_function,init = init,neuron1 = neuron1,neuron2 = neuron2)\n",
        "\n",
        "# Build and fit the GridSearchCV\n",
        "\n",
        "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = KFold(),verbose = 10)\n",
        "grid_result = grid.fit(X_standardized,y)\n",
        "\n",
        "# Summarize the results\n",
        "print('Best : {}, using {}'.format(grid_result.best_score_,grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "  print('{},{} with: {}'.format(mean, stdev, param))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDJBA3YboLPU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}